{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DiffEqBaseTrackerExt [1ba67e42-7aa7-5162-ac9b-c09642cdebbf] (cache misses: wrong dep version loaded (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DistributionsADLazyArraysExt [1640c15e-5bc7-5daf-855c-3cb1bdbdee06] (cache misses: wrong dep version loaded (2))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling SimpleNonlinearSolveTrackerExt [ac004708-0488-5d74-bdd8-3e2743d441a0] (cache misses: wrong dep version loaded (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling OptimizationMTKExt [ead85033-3460-5ce4-9d4b-429d76e53be9] (cache misses: wrong dep version loaded (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling FastPowerTrackerExt [18c65b70-2546-5492-ac4c-dad4ac5611e8] (cache misses: wrong dep version loaded (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling AdvancedHMCOrdinaryDiffEqExt [b79d61f8-5e13-53f1-8c3e-d7d191782ea7] (cache misses: wrong dep version loaded (4))\n"
     ]
    }
   ],
   "source": [
    "using Serialization, Turing\n",
    "include(\"ode_problem.jl\");\n",
    "include(\"target_probability.jl\");\n",
    "include(\"bayesian_inference.jl\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Target Distribution for Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first input we need are data points and each point's associated standard deviation\n",
    "experiment_timecourse = deserialize(\"outputs/000_processed_active_G_timecourse.dict\")\n",
    "experiment_dose_response = deserialize(\"outputs/000_processed_active_G_dose_response.dict\");\n",
    "#reshape for input to target probability \n",
    "data_points = vcat(experiment_timecourse[\"response\"], experiment_dose_response[\"response\"])\n",
    "std_dev = vcat(fill(experiment_timecourse[\"average_error\"], length(experiment_timecourse[\"response\"])), \n",
    "fill(experiment_dose_response[\"average_error\"], length(experiment_dose_response[\"response\"])))\n",
    "\n",
    "#next input we need is an ode problem\n",
    "odesys, u0, tspan, p = return_ode_problem_default_inputs()\n",
    "odeprob = DifferentialEquations.ODEProblem(odesys, u0, tspan, p);\n",
    "\n",
    "#also need regularization hyperparameters\n",
    "#note - must convert from M to molecules to match units\n",
    "avogadros_constant = 6.022e23 \n",
    "regularization_hyperparams = Dict(\"mean\" => log10(1.01e-7*avogadros_constant), \"std_dev\" => 0.8, \"lambda\" => 1)\n",
    "regularization_hyperparams_theoretical = Dict(\"mean\" => log10(5.0e-9*avogadros_constant), \"std_dev\" => 1, \"lambda\" => 1)\n",
    "\n",
    "#and ode solver inputs for both timecourse simulation and dose response simulation\n",
    "solver_inputs_timecourse = return_ode_problem_solver_default_inputs(\"timecourse\")\n",
    "solver_inputs_dose_response = return_ode_problem_solver_default_inputs(\"dose_response\")\n",
    "\n",
    "#finally, ligand concentrations for dose respones simulation and normalization\n",
    "ligand_doses = experiment_dose_response[\"ligand_stimulation (molecules)\"];\n",
    "normalization_dose = experiment_dose_response[\"normalize_to_response_at_dose\"];\n",
    "all_ligand_doses = vcat(ligand_doses,normalization_dose);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target probability definition\n",
    "target_distribution_regularized = logprob_regularized(data_points, odeprob, std_dev, regularization_hyperparams, solver_inputs_timecourse, \n",
    "solver_inputs_dose_response, all_ligand_doses);\n",
    "\n",
    "target_distribution_regularized_theoretical = logprob_regularized(data_points, odeprob, std_dev, regularization_hyperparams_theoretical, solver_inputs_timecourse, \n",
    "solver_inputs_dose_response, all_ligand_doses);\n",
    "\n",
    "target_distribution_unregularized = logprob_unregularized(data_points, odeprob, std_dev, solver_inputs_timecourse, \n",
    "solver_inputs_dose_response, all_ligand_doses);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Affine Invariant Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Model{F, argnames, (), (), Targs, Tuple{}, DefaultContext} where {F, argnames, Targs}} with 3 entries:\n",
       "  \"regularized\"             => Model{typeof(logprob_regularized), (:data, :odep…\n",
       "  \"regularized_theoretical\" => Model{typeof(logprob_regularized), (:data, :odep…\n",
       "  \"unregularized\"           => Model{typeof(logprob_unregularized), (:data, :od…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affine invariant sampler parameters\n",
    "n_ensemble = 1\n",
    "n_walkers = 1000\n",
    "n_iterations = 1000\n",
    "\n",
    "#target probability\n",
    "target_probability = Dict(\"unregularized\"=>target_distribution_unregularized, \n",
    "\"regularized\"=>target_distribution_regularized, \"regularized_theoretical\"=>target_distribution_regularized_theoretical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mAt t=0.31956765289595584, dt was forced below floating point epsilon 5.551115123125783e-17, and step error estimate = 1.1174328294930196. Aborting. There is either an error in your model specification or the true solution is unstable (or the true solution can not be represented in the precision of Float64).\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SciMLBase ~/.julia/packages/SciMLBase/hJh6T/src/integrator_interface.jl:623\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mAt t=0.31956765289595584, dt was forced below floating point epsilon 5.551115123125783e-17, and step error estimate = 1.1174328294930196. Aborting. There is either an error in your model specification or the true solution is unstable (or the true solution can not be represented in the precision of Float64).\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SciMLBase ~/.julia/packages/SciMLBase/hJh6T/src/integrator_interface.jl:623\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mAt t=0.31956765289595584, dt was forced below floating point epsilon 5.551115123125783e-17, and step error estimate = 1.1174328294930196. Aborting. There is either an error in your model specification or the true solution is unstable (or the true solution can not be represented in the precision of Float64).\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SciMLBase ~/.julia/packages/SciMLBase/hJh6T/src/integrator_interface.jl:623\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "#initial run for both regularized and unregularized \n",
    "for i in [\"regularized_theoretical\", \"unregularized\", \"regularized\"]\n",
    "    affine_invariant_mcmc_firstrun(n_ensemble, n_walkers, n_iterations, target_probability[i], i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `n_ensemble` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `n_ensemble` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[3]:5"
     ]
    }
   ],
   "source": [
    "start = 31\n",
    "n_subchains = 40\n",
    "approach = \"regularized\"\n",
    "for i in start:n_subchains\n",
    "    affine_invariant_mcmc(n_ensemble, n_walkers, n_iterations, target_probability[approach], i, approach)\n",
    "end\n",
    "\n",
    "approach = \"unregularized\"\n",
    "for i in start:n_subchains\n",
    "    affine_invariant_mcmc(n_ensemble, n_walkers, n_iterations, target_probability[approach], i, approach)\n",
    "end\n",
    "\n",
    "approach = \"regularized_theoretical\"\n",
    "for i in start:n_subchains\n",
    "    affine_invariant_mcmc(n_ensemble, n_walkers, n_iterations, target_probability[approach], i, approach)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia(ml_informed_binding_affinity_10_threads) 1.11.1",
   "language": "julia",
   "name": "julia_ml_informed_binding_affinity_10_threads_-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
